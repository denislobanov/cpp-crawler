#include <iostream>
#include <chrono>

#include "file_db.hpp"
#include "page_data.hpp"
#include "robots_txt.hpp"
#include "netio.hpp"

#define USER_AGENT "crawler test_database"

using std::cout;
using std::endl;

int main(void)
{
    //
    // page_data_c test
    database<page_data_c> page_db("test_db", "page_table");
    page_data_c* test_page = new page_data_c;

    std::string test_url = "http://test_url.com/a_test_page.html";

    //create test data
    test_page->rank = 42;
    test_page->crawl_count = 2;
    test_page->last_crawl = std::chrono::system_clock::now();
    test_page->out_links = {"link 1", "link 2", "link 3", "link 4"};
    test_page->url = test_url;
    test_page->title = "page title";
    test_page->description = "multi-line description for\ntest page generated by test_database.cpp";
    test_page->meta = {"some", "keywords", "for", "testing"};

    //send to db
    cout<<"sending page to database.."<<endl;
    page_db.put_object(test_page, test_url);

    //flush page
    delete test_page;
    test_page = new page_data_c;

    //retrieve
    cout<<"reading from database.."<<endl;
    try {
        page_db.get_object(test_page, test_url);
    } catch(db_exception &e) {
        cout<<"db_exception - "<<e.what();
        delete test_page;
        return -1;
    }

    cout<<"page url: "<<test_page->url;
    cout<<"page rank: "<<test_page->rank<<endl;
    cout<<"crawl count: "<<test_page->crawl_count<<endl;
    cout<<"last crawl: "<<std::chrono::system_clock::to_time_t(test_page->last_crawl)<<endl;
    cout<<"page title: "<<test_page->title<<endl;
    cout<<"out links: "<<endl;
    for(auto& x: test_page->out_links)
        cout<<"\t"<<x<<endl;
    cout<<"meta: "<<endl;
    for(auto& x: test_page->meta)
        cout<<"\t"<<x<<endl;
    cout<<"description: ["<<test_page->description<<"]"<<endl;

    //free resources
    delete test_page;

    //
    // robots_txt test
    cout<<"\n---\ndatabase robots_txt test\n";
    database<robots_txt> robots_db("test_db", "robots_table");

    test_url = "www.geeksaresexy.net";
    netio my_netio(USER_AGENT);
    robots_txt* test_robots = new robots_txt("sdfsdfsdf", test_url);

    //fill robots with test data
    cout<<"filling robots_txt with data\n";
    test_robots->fetch(my_netio);

    cout<<"sending robots_txt to database.."<<endl;
    test_robots->last_visit = 42; //make chrono
    robots_db.put_object(test_robots, test_url);

    delete test_robots;
    test_robots = new robots_txt(USER_AGENT, test_url);

    cout<<"reading from database.."<<endl;
    robots_db.get_object(test_robots, test_url);

    cout<<"last visit: "<<test_robots->last_visit<<endl;
    cout<<"crawl delay: "<<test_robots->crawl_delay<<endl;
    cout<<"exclusion list: "<<endl;
    std::vector<std::string> exclusions_list;
    test_robots->export_exclusions(exclusions_list);
    for(auto& x: exclusions_list)
        std::cout<<x<<std::endl;

    //free resources
    cout<<"\n~~~\ndone!"<<endl;
    delete test_robots;
    return 0;
}
