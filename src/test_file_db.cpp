#include <iostream>
#include <chrono>

#include "file_db.hpp"
#include "page_data.hpp"
#include "robots_txt.hpp"
#include "netio.hpp"

#define USER_AGENT "crawler test_database"

using std::cout;
using std::endl;

int main(void)
{
    //
    // page_data_c test
    database<page_data_c> page_db("test_db", "page_table");
    page_data_c* read_page = new page_data_c;
    page_data_c* write_page = new page_data_c;

    std::string test_url = "http://test_url.com/a_test_page.html";

    //create test data
    write_page->rank = 42;
    write_page->crawl_count = 2;
    write_page->last_crawl = std::chrono::system_clock::now();
    write_page->out_links = {"link 1", "link 2", "link 3", "link 4"};
    write_page->url = test_url;
    write_page->title = "page title";
    write_page->description = "multi-line description for\ntest page generated by test_database.cpp";
    write_page->meta = {"some", "keywords", "for", "testing"};

    //send to db
    cout<<"sending page to database.."<<endl;
    page_db.put_object(write_page, test_url);

    //retrieve
    cout<<"reading from database.."<<endl;
    try {
        page_db.get_object(read_page, test_url);
    } catch(db_exception &e) {
        cout<<"db_exception - "<<e.what();
        delete read_page;
        delete write_page;
        return -1;
    }

    cout<<"page url: "<<read_page->url;
    cout<<"page rank: "<<read_page->rank<<endl;
    cout<<"crawl count: "<<read_page->crawl_count<<endl;
    cout<<"last crawl: "<<std::chrono::system_clock::to_time_t(read_page->last_crawl)<<endl;
    cout<<"page title: "<<read_page->title<<endl;
    cout<<"out links: "<<endl;
    for(auto& x: read_page->out_links)
        cout<<"\t"<<x<<endl;
    cout<<"meta: "<<endl;
    for(auto& x: read_page->meta)
        cout<<"\t"<<x<<endl;
    cout<<"description: ["<<read_page->description<<"]"<<endl;

    //free resources
    delete read_page;
    delete write_page;

    //
    // robots_txt test
    cout<<"\n---\ndatabase robots_txt test\n";
    database<robots_txt> robots_db("test_db", "robots_table");

    test_url = "www.geeksaresexy.net";
    netio my_netio(USER_AGENT);
    robots_txt* read_robots = new robots_txt(USER_AGENT, test_url, my_netio);
    robots_txt* write_robots = new robots_txt(USER_AGENT, test_url, my_netio);

    cout<<"sending robots_txt to database.."<<endl;
    robots_db.put_object(read_robots, test_url);

    cout<<"reading from database.."<<endl;
    robots_db.get_object(write_robots, test_url);
    cout<<"last visit: "<<std::chrono::system_clock::to_time_t(write_robots->last_visit())<<endl;
    cout<<"crawl delay: "<<write_robots->crawl_delay().count()<<endl;

    //free resources
    cout<<"\n~~~\ndone!"<<endl;
    delete read_robots;
    delete write_robots;
    return 0;
}
